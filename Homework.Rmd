---
title: "EDHEC PhD Finance 2022 - Econometrics Homework"
author: "Giovanni Maffei, Timo Predoehl"
output:
  pdf_document: default
  html_document:
    df_print: paged
  html_notebook: default
---

\section*{Question 1: Spurious Regressions (2 points)}

```{r set_up, message=TRUE, warning=TRUE, include=FALSE, paged.print=FALSE}
pkgs.installed <- installed.packages()
pkgs.required <- c("car", "AER", "stargazer", "tictoc", "quantmod", "xts", "readr", "latex2exp", "gridExtra", "summarytools", "qwraps2", "nortest", "moments", "xtable", "sm", "astsa", "tseries", "ggplot2", "ggplotgui", "shiny", "tidyverse", "gridExtra")
pkgs.missing <- pkgs.required[which(!pkgs.required %in% pkgs.installed)]
lapply(pkgs.missing, install.packages, character.only = TRUE)
lapply(pkgs.required, require, character.only = TRUE)

rm(list=ls()) # clear all variables from enviroment/workspace

independent_AR_simulation<- function(phi_vec, c_vec, sigma_u_vec, T){
  # Simulate two independent RW and run spurious regression
  
  # function to simulate K independent AR process with :
  # T       = n.f simulated dates (simulated sample size)
  # phi_vec = [\phi_1, ..., phi_N]' = autoregressive coefficients for each AR process
  # c_vec   = [c_1, ..., c_N] = constant in AR process
  # number of AR(1) processes to simulate
  N <- length(phi_vec) 
  
  # create empty matrix T X N that will contain all simulated AR processes
  AR_sim_mat <- NA*matrix(0,T+1,N) # empty vector ( (T+1) X 1 )
   u_sim_mat <- NA*matrix(0,T+1,N) # empty vector ( (T+1) X 1 )
  
  # loop over each AR process ind1
  for (ind1 in seq(1,N)) {
    #ind1 = 1
    c       <-       c_vec[ind1]
    phi     <-     phi_vec[ind1]
    sigma_u <- sigma_u_vec[ind1]

    # simulate vector of innovations zero mean, and sd given as input
    # set.seed(10000+ind1) # fix "seed" in order to produce same random numbers every time next line of code is called!
    u    <- rnorm(n = T+1, mean = 0, sd = sigma_u) #WN
    u_sim_mat[,ind1] <- u

    # generate starting observation for the process: 
    # unconditional mean (stationary processes) or 0 (for non-stat processes only!, as phi=1 and c/(1-phi)=NA)
    if (abs(phi)<1){
      AR_sim_mat[1,ind1] <- c/(1-phi) ; #start from unconditional value of the process
    } else{
      AR_sim_mat[1,ind1] <- 0 ; #start from unconditional value of the process
    }

    # simulate all other observations t=2 to T+1
    for (t in seq(2,T+1)) AR_sim_mat[t,ind1] <- phi*AR_sim_mat[t-1,ind1] + u[t]
  }

  # Output of function
  # 1 = simulated AR process
  # 2 = simulated innovations
  return(list(AR_sim_mat = AR_sim_mat, u_sim_mat = u_sim_mat))
}
```

\subsection*{1.a. [1 Point] Replicate the analysis leading to Figure 14.1 in Davidson MacKinnon (2005, book)}

```{r simulation, message=FALSE, warning=FALSE, include=FALSE}
# N. of MC simulations
# Nsim <- 20000
Nsim <- 200


# DGP parameters : as above #############
phi_vec     = c(1, 1, 0.8, 0.8)
c_vec       = c(0,0, 0, 0)
sigma_u_vec = c(1, 1, 1, 1) 
T           = c(6, 12, 60, 120, 240, 360, 480)

# empty matrix to store intercept, t-stat(intercept), beta, t-stat (beta), and R^2
MC_mat <- NA*matrix(data = 0, nrow = length(T)*Nsim, ncol = 21)
colnames(MC_mat) <- c(
  "T", 
  "spur_RW_intercept", "spur_RW_t_intercept", "spur_RW_beta", "spur_RW_t_beta", "spur_RW_R2",
  "valid_RW_intercept", "valid_RW_t_intercept", "valid_RW_beta", "valid_RW_t_beta", "valid_RW_R2",
  "spur_AR_intercept", "spur_AR_t_intercept", "spur_AR_beta", "spur_AR_t_beta", "spur_AR_R2",
  "valid_AR_intercept", "valid_AR_t_intercept", "valid_AR_beta", "valid_AR_t_beta", "valid_AR_R2"
  )

tic()
  for (t in T) {
    #t = 6
    t_idx <- which(t == T)
    for(sim_idx in seq(1,Nsim)) {
      # sim_idx = 1
      output_temp <- independent_AR_simulation(phi_vec, c_vec, sigma_u_vec, t)
      AR_sim <- output_temp$AR_sim_mat
      reg_sim_RW_SPURS  <- lm(AR_sim[,2] ~ AR_sim[,1])
      reg_sim_RW_VALID  <- lm(AR_sim[,2] ~ AR_sim[,1] + lag(AR_sim[,2]))
      reg_sim_AR_SPURS  <- lm(AR_sim[,4] ~ AR_sim[,3])
      reg_sim_AR_VALID  <- lm(AR_sim[,4] ~ AR_sim[,3] + lag(AR_sim[,4]))
      mat_idx = (t_idx-1) * Nsim + sim_idx
      MC_mat[mat_idx, 1] <- t  # T
      MC_mat[mat_idx, 2] <- summary(reg_sim_RW_SPURS)$coefficients[1,1]  # intercept : value
      MC_mat[mat_idx, 3] <- summary(reg_sim_RW_SPURS)$coefficients[1,3]  # intercept : t-stat
      MC_mat[mat_idx, 4] <- summary(reg_sim_RW_SPURS)$coefficients[2,1]  # beta : value
      MC_mat[mat_idx, 5] <- summary(reg_sim_RW_SPURS)$coefficients[2,3]  # beta : t-stat
      MC_mat[mat_idx, 6] <- summary(reg_sim_RW_SPURS)$r.squared          # R^2
      
      MC_mat[mat_idx, 7] <- summary(reg_sim_RW_VALID)$coefficients[1,1]  # intercept : value
      MC_mat[mat_idx, 8] <- summary(reg_sim_RW_VALID)$coefficients[1,3]  # intercept : t-stat
      MC_mat[mat_idx, 9] <- summary(reg_sim_RW_VALID)$coefficients[2,1]  # beta : value
      MC_mat[mat_idx, 10] <- summary(reg_sim_RW_VALID)$coefficients[2,3]  # beta : t-stat
      MC_mat[mat_idx, 11] <- summary(reg_sim_RW_VALID)$r.squared          # R^2
      
      MC_mat[mat_idx, 12] <- summary(reg_sim_AR_SPURS)$coefficients[1,1]  # intercept : value
      MC_mat[mat_idx, 13] <- summary(reg_sim_AR_SPURS)$coefficients[1,3]  # intercept : t-stat
      MC_mat[mat_idx, 14] <- summary(reg_sim_AR_SPURS)$coefficients[2,1]  # beta : value
      MC_mat[mat_idx, 15] <- summary(reg_sim_AR_SPURS)$coefficients[2,3]  # beta : t-stat
      MC_mat[mat_idx, 16] <- summary(reg_sim_AR_SPURS)$r.squared          # R^2
      
      MC_mat[mat_idx, 17] <- summary(reg_sim_AR_VALID)$coefficients[1,1]  # intercept : value
      MC_mat[mat_idx, 18] <- summary(reg_sim_AR_VALID)$coefficients[1,3]  # intercept : t-stat
      MC_mat[mat_idx, 19] <- summary(reg_sim_AR_VALID)$coefficients[2,1]  # beta : value
      MC_mat[mat_idx, 20] <- summary(reg_sim_AR_VALID)$coefficients[2,3]  # beta : t-stat
      MC_mat[mat_idx, 21] <- summary(reg_sim_AR_VALID)$r.squared          # R^2
    }  
  }
toc()
```

\subsubsection*{1.a.i}

Compute also for each sample size T the distribution of the $R^2$ of the MC simulations with either 7 separate histograms, or one unique figure where you report on the y-axis the 5%, 10% 25%, 50%, 75%, 90% and 95% quantiles of the distributions of the simulated $R^2$, and on the x-axis you have T = 6, 12, 60, 120, 240, 360, 480.

```{r charting_R2, echo=FALSE, fig.align='center', message=FALSE, warning=FALSE}
# Histogram of estimated t-statistics for beta vs. N(0,1)
MC_R2 <- MC_mat %>% 
  as.data.frame() %>% 
  as_tibble() %>%
  select(T, spur_RW_R2) %>% 
  mutate(T = as.factor(T))

graph1 <- ggplot(MC_R2, aes(x = spur_RW_R2)) +
  geom_histogram(color = "#787878", fill = "#0099F8", position = 'stack', binwidth = 0.05, aes(y = ..ndensity..)) + 
  geom_density(aes(y = ..ndensity..), lwd = .2,
               linetype = 1,
               colour = 2) +
  facet_grid( . ~ T, space = "free_x" ) +
  theme_bw() +
  ggtitle(label = TeX(r"(Distribution of $R^2$)")) + 
  theme(text = element_text(size = 8)) +
  scale_y_continuous(
    breaks = c(.5, .10, .25, .5, .75, .90, .95),
    labels = scales::percent
    ) +
  scale_x_continuous(
    breaks = c(.25, .5, .75 ,1),
    labels = scales::percent
  ) +
  ylab(label = "Quantile") + 
  xlab(label = TeX(r"($R^2$)"))
  

graph1


# ggplot_shiny(MC_R2)

```

```{=tex}
\newpage
\subsubsection*{1.a.ii}
```
Similarly (either with histograms, or with one plot of the quantiles) report the distributions of the estimates t-statistics for the test of the null H0 : $\beta_2 = 0$

```{r charting_t, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
MC_beta_dist <- MC_mat %>% 
  as.data.frame() %>% 
  as_tibble() %>%
  select(T, spur_RW_t_beta) %>% 
  mutate(T = as.factor(T))

graph1 <- ggplot(MC_beta_dist, aes(x = spur_RW_t_beta)) +
  geom_histogram(color = "#787878", fill = "#0099F8", position = 'stack', aes(y = ..ndensity..)) + 
  geom_density(aes(y = ..ndensity..), lwd = .2,
               linetype = 1,
               colour = 2) +
  facet_grid( . ~ T, space = "free_x" ) +
  theme_bw() +
  ggtitle(label = TeX(r"(Distribution of $t_\beta$)")) + 
  theme(text = element_text(size = 8)) +
  scale_y_continuous(
    breaks = c(.5, .10, .25, .5, .75, .90, .95),
    labels = scales::percent
    ) +
  # scale_x_continuous(
  #   breaks = c(.25, .5, .75 ,1),
  #   labels = scales::percent
  # ) +
  ylab(label = "Quantile") + 
  xlab(label = TeX(r"($t_\beta$)"))
  

graph1

```

```{=tex}
\newpage
\subsubsection*{1.a.iii}
```
Compute the empirical rejection frequencies (that is the empirical size of the tests), which is exactly the figure 14.1 in Davidson MacKinnon (2005, book).

```{r rejection_rate, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
# Empirical size of (asymptotic) t-test
# normal quantile for 5% two sided test:
alpha <- 0.05;
crit_value <- qnorm(1-(alpha/2))

MC_beta_reject <- MC_mat %>% 
  as.data.frame() %>% 
  as_tibble() %>%
  select(T, spur_RW_t_beta, valid_RW_t_beta, spur_AR_t_beta, valid_AR_t_beta) %>% 
  mutate(
    t_crit = crit_value,
    reject_spur_RW = ifelse(abs(spur_RW_t_beta) > t_crit,1,0),
    reject_valid_RW = ifelse(abs(valid_RW_t_beta) > t_crit,1,0),
    reject_spur_AR = ifelse(abs(spur_AR_t_beta) > t_crit,1,0),
    reject_valid_AR = ifelse(abs(valid_AR_t_beta) > t_crit,1,0)
    ) %>% 
  group_by(T) %>% 
  summarise(
    pct_reject_spur_RW = sum(reject_spur_RW)/Nsim,
    pct_reject_valid_RW = sum(reject_valid_RW)/Nsim,
    pct_reject_spur_AR = sum(reject_spur_AR)/Nsim,
    pct_reject_valid_AR = sum(reject_valid_AR)/Nsim,
    )

graph3 <- ggplot(MC_beta_reject, aes(x = T)) +
  geom_line(linetype = "dotted", aes(y = pct_reject_spur_RW)) +
  geom_line(linetype = "dotted", aes(y = pct_reject_valid_RW)) +
  geom_line(linetype = "solid", aes(y = pct_reject_spur_AR)) +
  geom_line(linetype = "solid", aes(y = pct_reject_valid_AR)) +
    labs(
    title = TeX(r"(% of regressions which reject $H_0: \beta = 0$)"), 
    subtitle = TeX(r"(with $t = \frac{\beta - 0}{\sigma_{\beta}}>1.96$)")
    ) +
  geom_text(aes(x = 400, y = 0.8, label = "spurious regression RW")) +
  geom_text(aes(x = 400, y = 0.5, label = "spurious regression AR(1)")) +
  geom_text(aes(x = 400, y = 0.25, label = "valid regression RW")) +
  geom_text(aes(x = 400, y = 0.05, label = "valid regression AR(1)")) +
  ylab(label = "%") +
  xlab(label = "T") +
  theme_bw() +
  theme(text = element_text(size = 8))
  

graph3
```

\subsection*{1.b [1 Point] Based on the results obtained by answering to point (a) summarize the problems of spurious regressions in econometrics.}

Spurious regression as outlined in Davidson MacKinnon occurs for two reasons:

```{=tex}
\begin{enumerate}
  \item incorrectly specified $H_0$ and
  \item standard asymptotic results do not hold whenever at least one of the regressors is I(1), even when a model is correctly specified
\end{enumerate}
```
The $H_0: \beta_2=0$ tested with the model (14.12) $$y_t = \beta_1 + \beta_2y_{t-1} + v_t$$ implies a DGP': $y_t = \beta_1 + v_t$, when $y_t$ is actually generated using DGP (14.01) $y_t = y_{t-1} + v_t, y_0=0, v_t \sim iidN(0,1)$.

The wrongly specified $H_0$ is rejected with increasing frequency in n. This merely confirms that $y_t$ is not generated by the implied DGP'. Correctly specifying the model as (14.13) $$y_t = \beta_1 + \beta_2 x_t + \beta_3 y_{t-1} + v_t$$ and testing $H_0:\beta_2=0$, implying $\beta_3=1$ reduces the model to the actual DGP (14.01). This treatment, however, does not completely eliminate the problem i.e. leaves the rejection rate still significantly above 0.

For $\hat{\beta}$ to converge to $\beta_0$ asymtotically, the bias $(\hat{\beta} - \beta_0)$ must be $O_p(1)$: \begin{align*}
  (\hat{\beta} - \beta_0) &= (X'X)^{-1}X'u, with\\
  (X'X)^{-1} &\in O_p(n^{-1}) and \\
  X'u &\in O_p(n^{.5}). consequently:\\
  n^{.5}(\hat{\beta} - \beta_0) &= n^{.5}(X'X)^{-1}X'u = n^{.5} O_p(n^{-1})O_p(n^{.5}) = O_p(1)
\end{align*}

The relevant assumption to be tested is therefore is $(X'X) \in n^{.5} O_p(n^{-1})$.

The random walk (14.01) is I(1), due to: \begin{align*}
  w_t &= w_{t-1}+\epsilon_t \\
  w_t - w_{t-1} &= \epsilon_t \\
  (1-L)w_t  &= \epsilon_t \\
  (1-\phi(z))w_t &= \epsilon_t \\
  \phi(z) &= 1
\end{align*} Consequently, both $x_t$ and $y_t$ are I(1).

Further, (14.01) reduces to $w_t = \sum^t_{s=1}{\epsilon_s}$, which enters as X'X or: \begin{align*}
  \sum_{t=1}^n \left( \sum_{r=1}^t \sum_{s=1}^t \right) \epsilon_r \epsilon_s &= \sum_{t=1}^n \sum_{r=1}^t E(\epsilon_r^2), \epsilon_r\epsilon_s=0 \;\forall r \ne s\\
  \sum_{t=1}^n \sum_{r=1}^t \sigma^2 &= \sum_{t=1}^n \sum_{r=1}^t 1 \\
  \sum_{t=1}^n t  &= \frac{1}{2}n(n+1)
\end{align*}

Consequently, given (14.01) being I(1), $X'X \in O_p(n^2)$ and therefore cannot possibly converge to a finite probability limit. The bias $(\hat{\beta} - \beta_0)$ therefore does not converge asymptotically in probability.

\section*{Question 2: Time Series regression test of CAPM for one asset i (3 points)}
Black, Jensen and Scholes (1972) suggest to test the empirical validity of the CAPM by estimating the following LRM: 

\begin{align*}
	r_{it} - r_{ft} &= \alpha_i + \beta_i(r_{mt} - r_{ft}) + u_{it}\\
	z_{it} &= \alpha_i + \beta_i z_{mt} + u_{it}\\
	u_{it}|z_{mt} &\sim iid(0, \omega^2_i)
\end{align*}

\subsection*{(i) Estimate $\hat{\alpha_i}$ and $\hat{\beta_i}$}
NOTE : $\hat{\alpha_i}$ is the Jensenâ€™s alpha, and represents an estimate of the expected return not justified by its exposure to market risk, the only one that matters according to the CAPM.

\begin{align*}
	x_t &= (1, z_{mt}') \\
	X &= [x_1, ..., x_T]' \\
	X'X &= T Sxx\\
	Sxx &= \frac{1}{T}X'X = \left[\begin{array}{cc}
		1 & \bar{z}_m \\
		\bar{z}_m & \frac{1}{T}\sum{z_m^2}
	\end{array}\right] \\	
	Sxx^{-1} &= \left[\begin{array}{cc}
		\frac{1}{T}\sum{z_m^2} & -\bar{z}_m \\
		-\bar{z}_m & 1
	\end{array}\right] = \left[\begin{array}{cc}
	\frac{1}{T}\sum{z_m^2} - \bar{z}_m^2 + \bar{z}_m^2 & -\bar{z}_m \\
	-\bar{z}_m & 1
	\end{array}\right]\\
	 &= \left[\begin{array}{cc}
		\hat{\sigma}_m^2 + \bar{z}_m^2 & -\bar{z}_m \\
		-\bar{z}_m & 1
	\end{array}\right] = \left[\begin{array}{cc}
	1 + \frac{\bar{z}_m^2}{\hat{\sigma}_m^2} & \frac{-\bar{z}_m}{\hat{\sigma}_m^2} \\
	\frac{-\bar{z}_m}{\hat{\sigma}_m^2} & \frac{1}{\hat{\sigma}^2}
	\end{array}\right]\\
	Sxz_i &= X'z_i = \left[\begin{array}{c}
		\bar{z}_i \\
		\frac{1}{T}\sum{z_m z_i}
	\end{array}\right] = \left[\begin{array}{c}
		\bar{z}_i \\
		\frac{1}{T}\sum{z_m z_i} - \bar{z}_m \bar{z}_i + \bar{z}_m \bar{z}_i
	\end{array}\right] = \left[\begin{array}{c}
		\bar{z}_i \\
		\hat{\sigma}_{im} + \bar{z}_m \bar{z}_i 
	\end{array}\right] \\
\end{align*}

Solving for $\hat{\alpha}_i$ and $\hat{\beta}_i$:
\begin{align*}
		Sxx \left[\begin{array}{c}
		\hat{\alpha}_i \\
		\hat{\beta}_i
	\end{array}\right] & = Sxz_i\\
	\left[\begin{array}{cc}
		1 & \bar{z}_m \\
		\bar{z}_m & \frac{1}{n}\sum{z_m^2}
	\end{array}\right] \left[\begin{array}{c}
		\hat{\alpha}_i \\
		\hat{\beta}_i
	\end{array}\right] &= \left[\begin{array}{c}
		\bar{z}_i \\
		\hat{\sigma}_{im} + \bar{z}_m \bar{z}_i 
	\end{array}\right] \\	
	\begin{array}{c}
		(1) \\
		(2)
	\end{array}
	\left[\begin{array}{c}
		\hat{\alpha}_i + \hat{\beta}_i \bar{z}_m \\
		\hat{\alpha}_i \bar{z}_m + \hat{\beta}_i \frac{1}{n}\sum{z_m^2}
	\end{array}\right] &= \left[\begin{array}{c}
		\bar{z}_i \\
		\hat{\sigma}_{im} + \bar{z}_m \bar{z}_i 
	\end{array}\right] \\
\end{align*}

From (1) follows directly: $\hat{\alpha}_i = \bar{z}_i - \hat{\beta}_i \bar{z}_m$. Inserting this into (2) yields:
\begin{align*}
	\hat{\alpha}_i \bar{z}_m + \hat{\beta}_i \frac{1}{n}\sum{z_m^2} &= \hat{\sigma}_{im} + \bar{z}_m \bar{z}_i \\
	(\bar{z}_i - \hat{\beta}_i \bar{z}_m)\bar{z}_m + \hat{\beta}_i \frac{1}{n}\sum{z_m^2} &= \hat{\sigma}_{im} + \bar{z}_m \bar{z}_i \\
	\bar{z}_i \bar{z}_m - \hat{\beta}_i \bar{z}_m^2 + \hat{\beta}_i \frac{1}{n}\sum{z_m^2} &= \hat{\sigma}_{im} + \bar{z}_m \bar{z}_i \\
	- \hat{\beta}_i \bar{z}_m^2 + \hat{\beta}_i \frac{1}{n}\sum{z_m^2} &= \hat{\sigma}_{im}\\
	\hat{\beta}_i  (\frac{1}{n}\sum{z_m^2}-\bar{z}_m^2) &= \hat{\sigma}_{im}\\
	\hat{\beta}_i \hat{\sigma}_{m}^2 &= \hat{\sigma}_{im}\\
	\hat{\beta}_i &=  \frac{\hat{\sigma}_{im}}{\hat{\sigma}_{m}^2}\\
\end{align*}

\subsection*{(ii) Distribution of  $\hat{\alpha}_i$ and $\hat{\beta}_i$}

Expected value of $\hat{\alpha_i}$ and $\hat{\beta_i}$
\begin{align*}
	\hat{\beta} &= \left[\begin{array}{c}
		\hat{\alpha}_i \\
		\hat{\beta}_i
	\end{array}\right] = (X'X)^{-1}X'z_i = (X'X)^{-1}X'(X \beta + u_{it})\\
	E[\hat{\beta}|z_m] &= (X'X)^{-1}X'X \beta + (X'X)^{-1}X'E[u_{it}|z_m]\\
	E[\hat{\beta}|z_m] &= \beta + (X'X)^{-1}X'0, \text{ by assumption } u_i|z_mt \sim iid(0, \omega_i^2)\\
	E[\hat{\beta}|z_m] &= \beta\\
	E\left[\begin{array}{c}
		\hat{\alpha}_i \\
		\hat{\beta}_i
	\end{array}|z_m\right] &= \left[\begin{array}{c}
	\alpha_i \\
	\beta_i
\end{array}\right]
\end{align*}

Variance $\hat{\alpha}_i$ and $\hat{\beta}_i$
\begin{align*}
	\hat{\beta} &= \left[\begin{array}{c}
		\hat{\alpha}_i \\
		\hat{\beta}_i
	\end{array}\right]\\
	V(\hat{\beta}|z_m) &= V((\hat{\beta} - \beta)|z_m) \text{ (given $\beta$ non-random)}\\
	&= V((X'X)^{-1}X'u_{i}|z_m) = A V(u_{i}|z_m)A' \text{ (with $A=(X'X)^{-1}X'$)}\\
	&= A E[u_{i}^2|z_m] A' = A \omega_i^2A' \text{ by assumption } u_i|z_mt \sim iid(0, \omega_i^2)\\
	&= \omega_i^2AA' = \omega_i^2(X'X)^{-1}X'((X'X)^{-1}X')' = \omega_i^2(X'X)^{-1}X'X(X'X)^{-1}\\
	&= \omega_i^2 (X'X)^{-1} = \omega_i^2 \frac{1}{T}Sxx^{-1}\\
	&= \frac{\omega_i^2}{T}Sxx^{-1} = \frac{\omega_i^2}{T} \left[\begin{array}{cc}
		1 + \frac{\bar{z}_m^2}{\hat{\sigma}_m^2} & \frac{-\bar{z}_m}{\hat{\sigma}_m^2} \\
		\frac{-\bar{z}_m}{\hat{\sigma}_m^2} & \frac{1}{\hat{\sigma}^2}
	\end{array}\right]
\end{align*}

Therefore

\begin{align*}
	\left[\begin{array}{c}
		\hat{\alpha}_i \\
		\hat{\beta}_i
	\end{array}\right] | z_m &\sim N\left(
		\left[\begin{array}{c}
			\alpha_i \\
			\beta_i
		\end{array}\right], 
		\frac{\omega_i^2}{T} \left[\begin{array}{cc}
			1 + \frac{\bar{z}_m^2}{\hat{\sigma}_m^2} & \frac{-\bar{z}_m}{\hat{\sigma}_m^2} \\
			\frac{-\bar{z}_m}{\hat{\sigma}_m^2} & \frac{1}{\hat{\sigma}^2}
		\end{array}\right]
	\right) \square
\end{align*}

\subsection*{(iii) Determine the t-statistics to test $H_0: \beta_{k=1} = \alpha_i = 0$}

Analog to (ii) and replacing the unknown true $\omega_i$ with the sample $\hat{\omega}_i$ obtained from the OLS residuals
\begin{align*}
	V((\hat{\beta} - \beta)|z_m) &= \hat{\omega}_i^2 (X'X)^{-1} = \hat{\omega}_i^2 \frac{1}{T}Sxx^{-1}\\
	V((\hat{\beta}_{k=1} - 0)|z_m) &= \omega_i^2 (X'X)_{kk}^{-1} = \hat{\omega}_i^2 \frac{1}{T}Sxx_{kk}^{-1}\\
	&=  \frac{\hat{\omega}_i^2}{T}(1+\frac{\bar{z}_m^2}{\hat{\sigma}_m^2})\\
	SE((\hat{\beta} - \beta)|z_m) &= \hat{\omega}_i[(1+\frac{\bar{z}_m^2}{\hat{\sigma}_m^2})/T]^{1/2}
\end{align*}

The t-statistic to test $H_0: \beta_{k=1} = \alpha_i = 0$ therefore is : $$ \xi_i = \frac{\hat{\alpha}_i - 0}{\hat{\omega}_i[(1+\frac{\bar{z}_m^2}{\hat{\sigma}_m^2})/T]^{1/2}}  \xrightarrow{d}  N(0,1)$$