---
title: "EDHEC PhD Finance 2022 - Econometrics Homework"
author: "Giovanni Maffei, Timo Predoehl"
output:
  pdf_document: default
  html_document:
    df_print: paged
  html_notebook: default
---



\section*{Question 1: Spurious Regressions (2 points)} 
```{r set_up, message=TRUE, warning=TRUE, include=FALSE, paged.print=FALSE}
pkgs.installed <- installed.packages()
pkgs.required <- c("car", "AER", "stargazer", "tictoc", "quantmod", "xts", "readr", "latex2exp", "gridExtra", "summarytools", "qwraps2", "nortest", "moments", "xtable", "sm", "astsa", "tseries", "ggplot2", "ggplotgui", "shiny", "tidyverse", "gridExtra")
pkgs.missing <- pkgs.required[which(!pkgs.required %in% pkgs.installed)]
lapply(pkgs.missing, install.packages, character.only = TRUE)
lapply(pkgs.required, require, character.only = TRUE)

rm(list=ls()) # clear all variables from enviroment/workspace

independent_AR_simulation<- function(phi_vec, c_vec, sigma_u_vec, T){
  # Simulate two independent RW and run spurious regression
  
  # function to simulate K independent AR process with :
  # T       = n.f simulated dates (simulated sample size)
  # phi_vec = [\phi_1, ..., phi_N]' = autoregressive coefficients for each AR process
  # c_vec   = [c_1, ..., c_N] = constant in AR process
  # number of AR(1) processes to simulate
  N <- length(phi_vec) 
  
  # create empty matrix T X N that will contain all simulated AR processes
  AR_sim_mat <- NA*matrix(0,T+1,N) # empty vector ( (T+1) X 1 )
   u_sim_mat <- NA*matrix(0,T+1,N) # empty vector ( (T+1) X 1 )
  
  # loop over each AR process ind1
  for (ind1 in seq(1,N)) {
    #ind1 = 1
    c       <-       c_vec[ind1]
    phi     <-     phi_vec[ind1]
    sigma_u <- sigma_u_vec[ind1]

    # simulate vector of innovations zero mean, and sd given as input
    # set.seed(10000+ind1) # fix "seed" in order to produce same random numbers every time next line of code is called!
    u    <- rnorm(T+1, mean = 0, sd = sigma_u) #WN
    u_sim_mat[,ind1] <- u

    # generate starting observation for the process: 
    # unconditional mean (stationary processes) or 0 (for non-stat processes only!, as phi=1 and c/(1-phi)=NA)
    if (abs(phi)<1){
      AR_sim_mat[1,ind1] <- c/(1-phi) ; #start from unconditional value of the process
    } else{
      AR_sim_mat[1,ind1] <- 0 ; #start from unconditional value of the process
    }

    # simulate all other observations t=2 to T+1
    for (t in seq(2,T+1)) AR_sim_mat[t,ind1] <- phi*AR_sim_mat[t-1,ind1] + u[t]
  }

  # Output of function
  # 1 = simulated AR process
  # 2 = simulated innovations
  return(list(AR_sim_mat = AR_sim_mat, u_sim_mat = u_sim_mat))
}
```

\subsection*{1.a. [1 Point] Replicate the analysis leading to Figure 14.1 in Davidson MacKinnon (2005, book)}
```{r simulation, message=FALSE, warning=FALSE, include=FALSE}
# N. of MC simulations
Nsim <- 200

# DGP parameters : as above #############
phi_vec     = c(1, 1)
c_vec       = c(0,0)
sigma_u_vec = c(1,1) 
T           = c(6, 12, 60, 120, 240, 360, 480)

# empty matrix to store intercept, t-stat(intercept), beta, t-stat (beta), and R^2
MC_mat <- NA*matrix(data = 0, nrow = length(T)*Nsim, ncol = 6)
colnames(MC_mat) <- c("T", "intercept", "t_intercept", "beta", "t_beta", "R2")

tic()
  for (t in T) {
    #t = 6
    t_idx <- which(t == T)
    for(sim_idx in seq(1,Nsim)) {
      # sim_idx = 1
      output_temp <- independent_AR_simulation(phi_vec, c_vec, sigma_u_vec, t)
      AR_sim <- output_temp$AR_sim_mat
      reg_sim  <- lm(AR_sim[,2] ~ AR_sim[,1])
      mat_idx = (t_idx-1) * Nsim + sim_idx
      MC_mat[mat_idx, 1] <- t  # T
      MC_mat[mat_idx, 2] <- summary(reg_sim)$coefficients[,1][1]  # intercept : value
      MC_mat[mat_idx, 3] <- summary(reg_sim)$coefficients[,3][1]  # intercept : t-stat
      MC_mat[mat_idx, 4] <- summary(reg_sim)$coefficients[,1][2]  # beta : value
      MC_mat[mat_idx, 5] <- summary(reg_sim)$coefficients[,3][2]  # beta : t-stat
      MC_mat[mat_idx, 6] <- summary(reg_sim)$r.squared            # R^2
    }  
  }
toc()
```

\subsubsection*{1.a.i} Compute also for each sample size T the distribution of the $R^2$ of the MC simulations with either 7 separate histograms, or one unique figure where you report on the y-axis the 5%, 10% 25%, 50%, 75%, 90% and 95% quantiles of the distributions of the simulated $R^2$, and on the x-axis you have T = 6, 12, 60, 120, 240, 360, 480.
```{r charting_R2, echo=FALSE, fig.align='center', message=FALSE, warning=FALSE}
# Histogram of estimated t-statistics for beta vs. N(0,1)
MC_R2 <- MC_mat %>% 
  as.data.frame() %>% 
  as_tibble() %>%
  select(T, R2) %>% 
  mutate(T = as.factor(T))

graph1 <- ggplot(MC_R2, aes(x = R2)) +
  geom_histogram(color = "#787878", fill = "#0099F8", position = 'stack', binwidth = 0.05, aes(y = ..ndensity..)) + 
  geom_density(aes(y = ..ndensity..), lwd = .2,
               linetype = 1,
               colour = 2) +
  facet_grid( . ~ T, space = "free_x" ) +
  theme_bw() +
  ggtitle(label = TeX(r"(Distribution of $R^2$)")) + 
  theme(text = element_text(size = 8)) +
  scale_y_continuous(
    breaks = c(.5, .10, .25, .5, .75, .90, .95),
    labels = scales::percent
    ) +
  scale_x_continuous(
    breaks = c(.25, .5, .75 ,1),
    labels = scales::percent
  ) +
  ylab(label = "Quantile") + 
  xlab(label = TeX(r"($R^2$)"))
  

graph1


# ggplot_shiny(MC_R2)

```

\newpage
\subsubsection*{1.a.ii} Similarly (either with histograms, or with one plot of the quantiles) report the distributions of the estimates t-statistics for the test of the null H0 : $\beta_2 = 0$
```{r charting_t, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
MC_beta_dist <- MC_mat %>% 
  as.data.frame() %>% 
  as_tibble() %>%
  select(T, t_beta) %>% 
  mutate(T = as.factor(T))

graph1 <- ggplot(MC_beta_dist, aes(x = t_beta)) +
  geom_histogram(color = "#787878", fill = "#0099F8", position = 'stack', aes(y = ..ndensity..)) + 
  geom_density(aes(y = ..ndensity..), lwd = .2,
               linetype = 1,
               colour = 2) +
  facet_grid( . ~ T, space = "free_x" ) +
  theme_bw() +
  ggtitle(label = TeX(r"(Distribution of $t_\beta$)")) + 
  theme(text = element_text(size = 8)) +
  scale_y_continuous(
    breaks = c(.5, .10, .25, .5, .75, .90, .95),
    labels = scales::percent
    ) +
  # scale_x_continuous(
  #   breaks = c(.25, .5, .75 ,1),
  #   labels = scales::percent
  # ) +
  ylab(label = "Quantile") + 
  xlab(label = TeX(r"($t_\beta$)"))
  

graph1

```

\newpage
\subsubsection*{1.a.iii} their empirical rejection frequencies (that is the empirical size of the tests), which is exactly the figure 14.1 in Davidson MacKinnon (2005, book).
```{r rejection_rate, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
# Empirical size of (asymptotic) t-test
# normal quantile for 5% two sided test:
alpha <- 0.05;
crit_value <- qnorm(1-(alpha/2))
MC_beta_reject <- MC_mat %>% 
  as.data.frame() %>% 
  as_tibble() %>%
  mutate(
    t_crit = crit_value,
    reject = ifelse(t_beta > t_crit,1,0)
    ) %>% 
  group_by(T) %>% 
  summarise(pct_reject = sum(reject)/Nsim)

graph3 <- ggplot(MC_beta_reject, aes(x = T, y = pct_reject)) +
  geom_line() +
    labs(
    title = TeX(r"(% of regressions which reject $H_0: \beta = 0$)"), 
    subtitle = TeX(r"(with $t = \frac{\beta - 0}{\sigma_{\beta}}>1.96$)")
    ) +
  ylab(label = "%") +
  xlab(label = "T") +
  theme_bw()

graph3
```

\begin{enumerate}
  \item "Spurious regression, random walk" (14.12) $y_t = \beta_1 + \beta_2 x_t + _vt$
  \begin{itemize}
    \item why does the RR top out at 40-50%? Should be 100\%
  \end{itemize}
  \item "Valid regression, random walk" (14.13) $y_t = \beta_1 + \beta_2 x_t + \beta_3 y_{t-1} + v_t,$
  \item "Spurious regression, AR(1) process" (14.12), whereby $x_t$ and $y_t$ are generated by AR(1) with $\phi = 0.8$.
  \item "Valid regression, AR(1) process" (14.13), whereby $x_t$ and $y_t$ are generated by AR(1) with $\phi = 0.8$.
\end{enumerate}


\subsection*{1.b [1 Point] Based on the results obtained by answering to point (a) summarize the problems of spurious regressions in econometrics.}



